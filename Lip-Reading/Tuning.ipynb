{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_7AhiT3ydwn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "model_bn = Sequential()\n",
        "\n",
        "model_bn.add(Conv3D(64, (3, 3, 3), strides=1, input_shape=(22, 100, 100, 3), activation='relu', padding='valid'))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model_bn.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model_bn.add(Conv3D(256, (2, 2, 2), activation='relu', strides=1))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model_bn.add(Conv3D(512, (1, 1, 1), activation='relu', strides=1))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(MaxPooling3D(pool_size=(1, 1, 1), strides=2))\n",
        "\n",
        "# FC layers group\n",
        "model_bn.add(Flatten())\n",
        "model_bn.add(Dense(4096, activation='relu'))\n",
        "model_bn.add(Dropout(0.5))\n",
        "model_bn.add(Dense(2048, activation='relu'))\n",
        "model_bn.add(Dropout(0.5))\n",
        "model_bn.add(Dense(1024, activation='relu'))\n",
        "model_bn.add(Dropout(0.5))\n",
        "model_bn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_bn.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "# Model with Learning Rate Scheduling\n",
        "model_lr_schedule = Sequential()\n",
        "\n",
        "model_lr_schedule.add(Conv3D(64, (3, 3, 3), strides=1, input_shape=(22, 100, 100, 3), activation='relu', padding='valid',kernel_initializer='he_normal'))\n",
        "model_lr_schedule.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model_lr_schedule.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1,kernel_initializer='he_normal'))\n",
        "model_lr_schedule.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model_lr_schedule.add(Conv3D(256, (2, 2, 2), activation='relu', strides=1,kernel_initializer='he_normal'))\n",
        "model_lr_schedule.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model_lr_schedule.add(Conv3D(512, (1, 1, 1), activation='relu', strides=1,kernel_initializer='he_normal'))\n",
        "model_lr_schedule.add(MaxPooling3D(pool_size=(1, 1, 1), strides=2))\n",
        "\n",
        "# FC layers group\n",
        "model_lr_schedule.add(Flatten())\n",
        "model_lr_schedule.add(Dense(4096, activation='relu'))\n",
        "model_lr_schedule.add(Dropout(0.5))\n",
        "model_lr_schedule.add(Dense(2048, activation='relu'))\n",
        "model_lr_schedule.add(Dropout(0.5))\n",
        "model_lr_schedule.add(Dense(1024, activation='relu'))\n",
        "model_lr_schedule.add(Dropout(0.5))\n",
        "model_lr_schedule.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "#def scheduler(epoch, lr):\n",
        " #   return lr * 0.1\n",
        "\n",
        "#lr_schedule = LearningRateScheduler(scheduler)\n",
        "model_lr_schedule.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "i5sK2gvmy_qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# 1st layer group\n",
        "model.add(Conv3D(64, (3, 3, 3), strides = 1, input_shape=(22, 100, 100, 3), activation='relu', padding='valid'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model.add(Conv3D(256, (2, 2, 2), activation='relu', strides=1))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model.add(Conv3D(512, (1, 1, 1), activation='relu', strides=1))\n",
        "model.add(MaxPooling3D(pool_size=(1, 1, 1), strides=2))\n",
        "\n",
        "model.add((Flatten()))\n",
        "\n",
        "# # FC layers group\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Dense(2048, activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "uRNjND3UzDHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with Different Initialization\n",
        "from keras.initializers import he_normal\n",
        "model_he_normal = Sequential()\n",
        "\n",
        "model_he_normal.add(Conv3D(64, (3, 3, 3), strides=1, input_shape=(22, 100, 100, 3), activation='relu', padding='valid', kernel_initializer='he_normal'))\n",
        "model_he_normal.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model_he_normal.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1, kernel_initializer='he_normal'))\n",
        "model_he_normal.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model_he_normal.add(Conv3D(256, (2, 2, 2), activation='relu', strides=1, kernel_initializer='he_normal'))\n",
        "model_he_normal.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model_he_normal.add(Conv3D(512, (1, 1, 1), activation='relu', strides=1, kernel_initializer='he_normal'))\n",
        "model_he_normal.add(MaxPooling3D(pool_size=(1, 1, 1), strides=2))\n",
        "\n",
        "# FC layers group\n",
        "model_he_normal.add(Flatten())\n",
        "model_he_normal.add(Dense(4096, activation='relu'))\n",
        "model_he_normal.add(Dropout(0.5))\n",
        "model_he_normal.add(Dense(2048, activation='relu'))\n",
        "model_he_normal.add(Dropout(0.5))\n",
        "model_he_normal.add(Dense(1024, activation='relu'))\n",
        "model_he_normal.add(Dropout(0.5))\n",
        "model_he_normal.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_he_normal.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "K9JC60TbzFpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "epochs=50\n",
        "# Train models\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "history_bn = model_bn.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val))\n",
        "history_lr_schedule = model_adam_lr.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val))\n",
        "history_he_normal = model_he_normal.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val))\n",
        "history_adam_optimizer = model_adam_optimizer.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val))\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Batch Normalization\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(history_bn.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_bn.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Batch Normalization')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Learning Rate Scheduling\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(history_lr_schedule.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_lr_schedule.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('LR')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Different Initialization\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(history_he_normal.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_he_normal.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Different Initialization')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Different Optimizer\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(history_adam_optimizer.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_adam_optimizer.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Different Optimizer (Adam)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-3BdY2rrzIcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xlim(1, 100)\n",
        "# plt.ylim(0, 3)\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GkJQbgN7zQll"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}